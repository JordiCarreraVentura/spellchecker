{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_Count': 10, 'nb_sent': 1000, 'freq_ratio': 10, 'chgram': 2, 'sim_thres': 0.9} hits = \"250\"  precision = \"0.919117647059\" recall = \"0.51867219917\" \n",
      "\n",
      "{'min_Count': 10, 'nb_sent': 1000, 'freq_ratio': 10, 'chgram': 2, 'sim_thres': 0.88} hits = \"286\"  precision = \"0.916666666667\" recall = \"0.598326359833\" \n",
      "\n",
      "{'min_Count': 10, 'nb_sent': 10000, 'freq_ratio': 10, 'chgram': 2, 'sim_thres': 0.85} hits = \"325\"  precision = \"0.905292479109\" recall = \"0.691489361702\" \n",
      "\n",
      "{'min_Count': 10, 'nb_sent': 10000, 'freq_ratio': 10, 'chgram': 2, 'sim_thres': 0.85} hits = \"325\"  precision = \"0.905292479109\" recall = \"0.691489361702\" \n",
      "\n",
      "{'min_Count': 10, 'nb_sent': 20000, 'freq_ratio': 10, 'chgram': 2, 'sim_thres': 0.9} hits = \"250\"  precision = \"0.919117647059\" recall = \"0.51867219917\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#    This is a test\n",
    "from __future__ import division\n",
    "corpus = 'data/delorme.com_shu.pages_89.txt'\n",
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from config import CONFIG\n",
    "\n",
    "from tests import tests1, tests2\n",
    "\n",
    "from normalizer import Normalizer\n",
    "from lib.CharacterIndex import CharacterIndex\n",
    "from lib.NaiveTokenizer import NaiveTokenizer\n",
    "from lib.TextStreamer import TextStreamer\n",
    "\n",
    "from lib.Tools import (\n",
    "    FreqDist,\n",
    "    tokenizer,\n",
    "    splitter\n",
    ")\n",
    "\n",
    "from collections import (\n",
    "    Counter,\n",
    "    defaultdict as deft\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def freq_ratio(maxim, minim, log_base=2.0):\n",
    "    if maxim < 10:\n",
    "        return False\n",
    "    multiplier = math.log(maxim, log_base)\n",
    "#     print maxim, minim, maxim / minim, multiplier, (multiplier * multiplier)\n",
    "    if maxim / minim >= (multiplier * multiplier):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_name(template):\n",
    "    i = 1\n",
    "    while True:\n",
    "        name = template % i\n",
    "        if not os.path.exists(name):\n",
    "            return name\n",
    "        i += 1\n",
    "\n",
    "for C in CONFIG:\n",
    "    \n",
    "    tests = tests1.items() + tests2.items()\n",
    "\n",
    "    #\tCollect input from large text file:\n",
    "    streamer = TextStreamer(corpus)\n",
    "\n",
    "    dump = []\n",
    "    for doc in streamer:\n",
    "        for sent in splitter(doc):\n",
    "            dump += tokenizer(sent)\n",
    "    freq_dist = Counter(dump)\n",
    "    \n",
    "\n",
    "    #\tMap all character n-grams to words, and all words to their\n",
    "    #\tcharacter n-grams\n",
    "    index = CharacterIndex(dump + tests, min_r=C['sim_thres'])\n",
    "    index.build()\n",
    "\n",
    "    \n",
    "    hits = 0\n",
    "    empty = 0\n",
    "\n",
    "\n",
    "    template = 'logs/test.%d.txt'\n",
    "    file = open(get_name(template), 'wb')\n",
    "    file.write('\\n'.join(['%s=%s' % (str(x), str(y)) for x, y in C.items()]) + '\\n')\n",
    "\n",
    "    for correct, error in tests:\n",
    "        similars = index[error]\n",
    "        if not similars:\n",
    "            empty += 1\n",
    "        f_w = freq_dist[error]\n",
    "        if not similars:\n",
    "            continue\n",
    "        similars.sort(\n",
    "            key=lambda x: freq_dist[x[0]],\n",
    "            reverse=True\n",
    "        )\n",
    "        if similars[0][0] == correct:\n",
    "            hits += 1\n",
    "    #        print error, '>', correct, hits, hits / float(len(tests) - empty)\n",
    "        else:\n",
    "            file.write('error=\"%s\"  hypothesis=\"%s\"  human=\"%s\"\\n' % (error, similars[0][0], correct))\n",
    "    file.write('hits = \"%s\"  precision = \"%s\" recall = \"%s\" \\n' % (hits, hits / float(len(tests) - empty), hits / (hits + empty)))\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "    print C, ('hits = \"%s\"  precision = \"%s\" recall = \"%s\" \\n' % (hits, hits / float(len(tests) - empty), hits / (hits + empty)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
